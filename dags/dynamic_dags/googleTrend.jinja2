from airflow import DAG
from airflow.decorators import task, task_group
from airflow.utils.trigger_rule import TriggerRule

from datetime import datetime, timezone
from plugins.slack import SlackAlert

import logging
import json
import os

country_codes = [
    "AU", "AT", "BE", "CA", "CL", "CZ", "DK", "EE", "FI", "FR", 
    "DE", "GR", "HU", "IS", "IE", "IT", "JP", "KR", "MX", "NL", 
    "NZ", "NO", "PL", "PT", "SK", "SI", "ES", "SE", "CH", "TR", 
    "GB", "US", 'WORLD'
]
kinds = ["it_time", "it_region", "rel_topics", "rel_queries"]


def send_slack_message():
    from plugins.awsfunc import awsfunc

    s3_handler = awsfunc('secretsmanager')
    slack_token = s3_handler.getapikey(secret_id="slack-token")
    slack_alert = SlackAlert(channel="#monitoring_airflow", token=slack_token)
    return slack_alert


@task
def get_topic_names_from_json_files(directory):
    topics = []
    for filename in os.listdir(directory):
        if filename.startswith("topic") and filename.endswith(".json"):
            file_path = os.path.join(directory, filename)
            with open(file_path, "r") as json_file:
                data = json.load(json_file)
                topics.extend(item.get("TOPIC_NM") for item in data if "TOPIC_NM" in item)
    return {'topics' : topics}


@task(pool="pytrend_pool")
def extract(keywords:dict):
    from plugins.pytrend import PyTrendsWrapper

    pytrend = PyTrendsWrapper()
    logging.info(f"[extract] 데이터 수집 시작")
    result = {kind: [] for kind in ["it_time", "it_region", "rel_topics", "rel_queries"]}
    for kind in kinds:
        logging.info(f"[extract] 데이터 수집 시작 - kind: {kind}")
        for keyword in keywords['topics']:
            for geo in country_codes:
                try:
                    response = pytrend.get_request(kind=kind, keyword=keyword, timeframe="now 7-d", geo=geo)
                    result[kind].append({
                        'response': response,
                        'keyword': keyword,
                        'geo': geo 
                    })
                except Exception as e:
                    logging.error(f"An error occurred: {e}")
                    continue
    return result


def transform_it_time(keyword, geo, response):
    import numpy as np
    
    if response.empty:
        return []

    response['TARGET_GEO_ID'] = geo
    response['TF_ID'] = "{{ tf_id }}"
    response['KEYWORD'] = keyword

    new_column_names = {'isPartial': 'ISPARTIAL', f"{keyword}" : 'IT_CNT'}
    response.rename(columns=new_column_names, inplace=True)
    response.fillna(np.nan).replace([np.nan], [None])
    
    response['date']= response['date'].dt.strftime('%Y-%m-%d %H:%M:%S')
    new_column_names = {'date':'IT_DATE'}
    response.rename(columns=new_column_names, inplace=True)

    result = response.to_dict(orient='records')
    return result


def transform_it_region(keyword, geo, response):
    import numpy as np

    if response.empty:
        return []

    if 'coordinates' in response:
        response['LAT'] = response['coordinates'].apply(lambda coord: coord['lat'] if isinstance(coord, dict) else None)
        response['LNG'] = response['coordinates'].apply(lambda coord: coord['lng'] if isinstance(coord, dict) else None)
        response.drop('coordinates', axis=1, inplace=True)

    response['TARGET_GEO_ID'] = geo
    response['TF_ID'] = "{{ tf_id }}"
    response['KEYWORD'] = keyword
    response.fillna(np.nan).replace([np.nan], [None])
    
    new_column_names = {'geoName': 'GEO_NAME', 'geoCode': 'GEO_CD', f"{keyword}" : 'IT_CNT'}
    response.rename(columns=new_column_names, inplace=True)

    result = response.to_dict(orient='records')
    return result


def transform_rel_topics(keyword, geo, response):
    import pandas as pd
    import numpy as np

    df_top = pd.DataFrame()
    df_rising = pd.DataFrame()

    if response.get(keyword) and response[keyword]['top'] is not None:
        df_top = response[keyword]['top'].reset_index()
        df_top['TREND_TYPE'] = 'top'
    if response.get(keyword) and response[keyword]['rising'] is not None:
        df_rising = response[keyword]['rising'].reset_index()
        df_rising['TREND_TYPE'] = 'rising'
    if df_rising.empty and df_top.empty:
        return []

    df_total = pd.concat([df_rising, df_top], ignore_index=True)
    df_total['TARGET_GEO_ID'] = geo
    df_total['TF_ID'] = "{{ tf_id }}"
    df_total['KEYWORD'] = keyword
    df_total.fillna(np.nan).replace([np.nan], [None])

    df_total.drop(['hasData', 'link', 'topic_mid'], axis=1, inplace=True)
    new_column_names = {'index': 'RANKING', 'value': 'VALUE', 'formattedValue' : 'FORMATTED_VALUE', 'topic_title' : 'TOPIC_NM', 'topic_type': 'TOPIC_TYPE'}
    df_total.rename(columns=new_column_names, inplace=True)

    result = df_total.to_dict(orient='records')
    return result


def transform_rel_queries(keyword, geo, response):
    import pandas as pd
    import numpy as np

    df_top = pd.DataFrame()
    df_rising = pd.DataFrame()

    if response.get(keyword) and response[keyword]['top'] is not None:
        df_top = response[keyword]['top'].reset_index()
        df_top['TREND_TYPE'] = 'top'
    if response.get(keyword) and response[keyword]['rising'] is not None:
        df_rising = response[keyword]['rising'].reset_index()
        df_rising['TREND_TYPE'] = 'rising'
    if df_rising.empty and df_top.empty:
        return []

    df_total = pd.concat([df_rising, df_top], ignore_index=True)
    df_total['TARGET_GEO_ID'] = geo
    df_total['TF_ID'] = "{{ tf_id }}"
    df_total['KEYWORD'] = keyword
    df_total.fillna(np.nan).replace([np.nan], [None])

    new_column_names = {'index': 'RANKING', 'value': 'QEURY_CNT', 'query': 'QUERY'}
    df_total.rename(columns=new_column_names, inplace=True)

    result = df_total.to_dict(orient='records')
    return result


@task
def transform(raw_data):
    logging.info(f"[transform] 데이터 변환 시작")

    result = {kind: [] for kind in ["it_time", "it_region", "rel_topics", "rel_queries"]}
    
    for item in raw_data['it_time']:
        result['it_time'].append(transform_it_time(keyword=item.get('keyword'), geo=item.get('geo'), response=item.get('response')))
    for item in raw_data['it_region']:
        result['it_region'].append(transform_it_region(keyword=item.get('keyword'), geo=item.get('geo'), response=item.get('response')))
    for item in raw_data['rel_topics']:
        result['rel_topics'].append(transform_rel_topics(keyword=item.get('keyword'), geo=item.get('geo'), response=item.get('response')))
    for item in raw_data['rel_queries']:
        result['rel_queries'].append(transform_rel_queries(keyword=item.get('keyword'), geo=item.get('geo'), response=item.get('response')))
    return result


@task
def load(transform_data):
    from plugins.awsfunc import awsfunc
    from plugins.file_ops import load_as_json
    import os

    s3_handler = awsfunc('s3')
    bucket_name = "de-2-2"

    for kind in kinds:
        for content in transform_data[kind]:
            file_key = f"raw/googletrend/{kind}/{{ dag_id }}.json"

            logging.info(f"[four_hour:{kind}] 데이터 저장 시작")
            s3_handler.ec2tos3(json.dumps(content), bucket_name, file_key)
            # dag_root_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            # load_as_json(file_path=dag_root_path, subpath=kind, filename="four_hour", content=content)


@task_group
def ETL(keywords:dict):
    load(transform(extract(keywords)))


with DAG(
    dag_id="g_trend_{{ dag_id }}",
    start_date=datetime(2023, 8, 29),
    schedule='{{ schedule }}',
    catchup={{ catchup }},
    on_success_callback=send_slack_message().success_alert,
    on_failure_callback=send_slack_message().fail_alert,
    max_active_runs=3,
    max_active_tasks=60
) as dag:

    dag_root_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__))) + "/data/topic"
    ETL(keywords=get_topic_names_from_json_files(dag_root_path))